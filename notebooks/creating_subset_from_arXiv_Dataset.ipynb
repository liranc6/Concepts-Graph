{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "\n",
    "\n",
    "ProjectPath = \"/home/liranc6/con_graph\"\n",
    "sys.path.append(ProjectPath)  # Add the parent directory to the sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mrambo6                    \u001b[m  Sun Apr 21 11:12:01 2024  \u001b[1m\u001b[30m525.147.05\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 87°C\u001b[m, \u001b[1m\u001b[32m 99 %\u001b[m | \u001b[1m\u001b[33m 9829\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshadi-omari\u001b[m(\u001b[33m9826M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 26°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 23°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 24°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 24°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "! gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mrambo6                    \u001b[m  Sun Apr 21 11:12:04 2024  \u001b[1m\u001b[30m525.147.05\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[1m\u001b[31m 87°C\u001b[m, \u001b[1m\u001b[32m 99 %\u001b[m | \u001b[1m\u001b[33m 9829\u001b[m / \u001b[33m24576\u001b[m MB | \u001b[1m\u001b[30mshadi-omari\u001b[m(\u001b[33m9826M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 26°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 23°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 24°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 25°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mNVIDIA GeForce RTX 3090\u001b[m |\u001b[31m 24°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[1m\u001b[33m    1\u001b[m / \u001b[33m24576\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "! gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/mnt/qnap/liranc6/data/con_graph/dataset/arxiv-metadata-oai-snapshot.json\"\n",
    "subset_metadata_path = \"/mnt/qnap/liranc6/data/con_graph/dataset/subset_metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(data_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            metadata = json.loads(line)\n",
    "            yield metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0704.0001\n",
      "submitter: Pavel Nadolsky\n",
      "authors: C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\n",
      "title: Calculation of prompt diphoton production cross sections at Tevatron and\n",
      "  LHC energies\n",
      "comments: 37 pages, 15 figures; published version\n",
      "journal-ref: Phys.Rev.D76:013009,2007\n",
      "doi: 10.1103/PhysRevD.76.013009\n",
      "report-no: ANL-HEP-PR-07-12\n",
      "categories: hep-ph\n",
      "license: None\n",
      "abstract:   A fully differential calculation in perturbative quantum chromodynamics is\n",
      "presented for the production of massive photon pairs at hadron colliders. All\n",
      "next-to-leading order perturbative contributions from quark-antiquark,\n",
      "gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\n",
      "all-orders resummation of initial-state gluon radiation valid at\n",
      "next-to-next-to-leading logarithmic accuracy. The region of phase space is\n",
      "specified in which the calculation is most reliable. Good agreement is\n",
      "demonstrated with data from the Fermilab Tevatron, and predictions are made for\n",
      "more detailed tests with CDF and DO data. Predictions are shown for\n",
      "distributions of diphoton pairs produced at the energy of the Large Hadron\n",
      "Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\n",
      "boson are contrasted with those produced from QCD processes at the LHC, showing\n",
      "that enhanced sensitivity to the signal can be obtained with judicious\n",
      "selection of events.\n",
      "\n",
      "versions: [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}]\n",
      "update_date: 2008-11-26\n",
      "authors_parsed: [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', ''], ['Yuan', 'C. -P.', '']]\n"
     ]
    }
   ],
   "source": [
    "metadata = get_metadata(data_path)\n",
    "for paper in metadata:\n",
    "    for k, v in paper.items():\n",
    "        print(f'{k}: {v}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping shortened names of months to numerical values\n",
    "month_mapping = {\n",
    "    'Jan': 1,\n",
    "    'Feb': 2,\n",
    "    'Mar': 3,\n",
    "    'Apr': 4,\n",
    "    'May': 5,\n",
    "    'Jun': 6,\n",
    "    'Jul': 7,\n",
    "    'Aug': 8,\n",
    "    'Sep': 9,\n",
    "    'Oct': 10,\n",
    "    'Nov': 11,\n",
    "    'Dec': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #count lines in file\n",
    "# num_lines = sum(1 for line in open(data_path))\n",
    "# print(num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_v1_submission_date(paper_info):\n",
    "    # Access the first version of the paper\n",
    "    v1_created_date = paper_info['versions'][0]['created']\n",
    "    \n",
    "    # Extracting only the month and year\n",
    "    v1_month_year = v1_created_date.split(',')[1].strip()\n",
    "\n",
    "    # Extract month and year separately\n",
    "    month, year = month_mapping[v1_month_year.split()[1]], int(v1_month_year.split()[2])\n",
    "    \n",
    "    return [month, year]\n",
    "\n",
    "# Function to save subset metadata to the file\n",
    "def append_to_file(subset_metadata, json_file_path):\n",
    "    with open(json_file_path, 'a') as json_file:\n",
    "        for e in subset_metadata:\n",
    "            json.dump(e, json_file)\n",
    "            json_file.write('\\n')  # Add newline for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_file(file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 papers\n",
      "Processed 100 papers\n",
      "Processed 200 papers\n",
      "Processed 300 papers\n",
      "Processed 400 papers\n",
      "Processed 500 papers\n",
      "Processed 600 papers\n",
      "Processed 700 papers\n",
      "Processed 800 papers\n",
      "Processed 900 papers\n",
      "Processed 1000 papers\n",
      "Processed 1100 papers\n",
      "Processed 1200 papers\n",
      "Processed 1300 papers\n",
      "Processed 1400 papers\n",
      "Processed 1500 papers\n",
      "Processed 1600 papers\n",
      "Processed 1700 papers\n",
      "Processed 1800 papers\n",
      "Processed 1900 papers\n",
      "Processed 2000 papers\n",
      "Processed 2100 papers\n",
      "Processed 2200 papers\n",
      "Processed 2300 papers\n",
      "Processed 2400 papers\n",
      "Processed 2500 papers\n",
      "Processed 2600 papers\n",
      "Processed 2700 papers\n",
      "Processed 2800 papers\n",
      "Processed 2900 papers\n",
      "Processed 3000 papers\n",
      "Processed 3100 papers\n",
      "Processed 3200 papers\n",
      "Processed 3300 papers\n",
      "Processed 3400 papers\n",
      "Processed 3500 papers\n",
      "Processed 3600 papers\n",
      "Processed 3700 papers\n",
      "Processed 3800 papers\n",
      "Processed 3900 papers\n",
      "Processed 4000 papers\n",
      "Processed 4100 papers\n",
      "Processed 4200 papers\n",
      "Processed 4300 papers\n",
      "Processed 4400 papers\n",
      "Processed 4500 papers\n",
      "Processed 4600 papers\n",
      "Processed 4700 papers\n",
      "Processed 4800 papers\n",
      "Processed 4900 papers\n",
      "Processed 5000 papers\n",
      "Processed 5100 papers\n",
      "Processed 5200 papers\n",
      "Processed 5300 papers\n",
      "Processed 5400 papers\n",
      "Processed 5500 papers\n",
      "Processed 5600 papers\n",
      "Processed 5700 papers\n",
      "Processed 5800 papers\n",
      "Processed 5900 papers\n",
      "Processed 6000 papers\n",
      "Processed 6100 papers\n",
      "Processed 6200 papers\n",
      "Processed 6300 papers\n",
      "Processed 6400 papers\n",
      "Processed 6500 papers\n",
      "Processed 6600 papers\n",
      "Processed 6700 papers\n",
      "Processed 6800 papers\n",
      "Processed 6900 papers\n",
      "Processed 7000 papers\n",
      "Processed 7100 papers\n",
      "Processed 7200 papers\n",
      "Processed 7300 papers\n",
      "Processed 7400 papers\n",
      "Processed 7500 papers\n",
      "Processed 7600 papers\n",
      "Processed 7700 papers\n",
      "Processed 7800 papers\n",
      "Processed 7900 papers\n",
      "Processed 8000 papers\n",
      "Processed 8100 papers\n",
      "Processed 8200 papers\n",
      "Processed 8300 papers\n",
      "Processed 8400 papers\n",
      "Processed 8500 papers\n",
      "Processed 8600 papers\n",
      "Processed 8700 papers\n",
      "Processed 8800 papers\n",
      "Processed 8900 papers\n",
      "Processed 9000 papers\n",
      "Processed 9100 papers\n",
      "Processed 9200 papers\n",
      "Processed 9300 papers\n",
      "Processed 9400 papers\n",
      "Processed 9500 papers\n",
      "Processed 9600 papers\n",
      "Processed 9700 papers\n",
      "Processed 9800 papers\n",
      "Processed 9900 papers\n",
      "Processed 10000 papers\n",
      "Processed 10100 papers\n",
      "Processed 10200 papers\n",
      "Processed 10300 papers\n",
      "Processed 10400 papers\n",
      "Processed 10500 papers\n",
      "Processed 10600 papers\n",
      "Processed 10700 papers\n",
      "Processed 10800 papers\n",
      "Processed 10900 papers\n",
      "Processed 11000 papers\n",
      "Processed 11100 papers\n",
      "Processed 11200 papers\n",
      "Processed 11300 papers\n",
      "Processed 11400 papers\n",
      "Processed 11500 papers\n",
      "Processed 11600 papers\n",
      "Processed 11700 papers\n",
      "Processed 11800 papers\n",
      "Processed 11900 papers\n",
      "Processed 12000 papers\n",
      "Processed 12100 papers\n",
      "Processed 12200 papers\n",
      "Processed 12300 papers\n",
      "Processed 12400 papers\n",
      "Processed 12500 papers\n",
      "Processed 12600 papers\n",
      "Processed 12700 papers\n",
      "Processed 12800 papers\n",
      "Processed 12900 papers\n",
      "Processed 13000 papers\n",
      "Processed 13100 papers\n",
      "Processed 13200 papers\n",
      "Processed 13300 papers\n",
      "Processed 13400 papers\n",
      "Processed 13500 papers\n",
      "Processed 13600 papers\n",
      "Processed 13700 papers\n",
      "Processed 13800 papers\n",
      "Processed 13900 papers\n",
      "Processed 14000 papers\n",
      "Processed 14100 papers\n",
      "Processed 14200 papers\n",
      "Processed 14300 papers\n",
      "Processed 14400 papers\n",
      "Processed 14500 papers\n",
      "Processed 14600 papers\n",
      "Processed 14700 papers\n",
      "Processed 14800 papers\n",
      "Processed 14900 papers\n",
      "Processed 15000 papers\n",
      "Processed 15100 papers\n",
      "Processed 15200 papers\n",
      "Processed 15300 papers\n",
      "Processed 15400 papers\n",
      "Processed 15500 papers\n",
      "Processed 15600 papers\n",
      "Processed 15700 papers\n",
      "Processed 15800 papers\n",
      "Processed 15900 papers\n",
      "Processed 16000 papers\n",
      "Processed 16100 papers\n",
      "Processed 16200 papers\n",
      "Processed 16300 papers\n",
      "Processed 16400 papers\n",
      "Processed 16500 papers\n",
      "Processed 16600 papers\n",
      "Processed 16700 papers\n",
      "Processed 16800 papers\n",
      "Processed 16900 papers\n",
      "Processed 17000 papers\n",
      "Processed 17100 papers\n",
      "Processed 17200 papers\n",
      "Processed 17300 papers\n",
      "Processed 17400 papers\n",
      "Processed 17500 papers\n",
      "Processed 17600 papers\n",
      "Processed 17700 papers\n",
      "Processed 17800 papers\n",
      "Processed 17900 papers\n",
      "Processed 18000 papers\n",
      "Processed 18100 papers\n",
      "Processed 18200 papers\n",
      "Processed 18300 papers\n",
      "Processed 18400 papers\n",
      "Processed 18500 papers\n",
      "Processed 18600 papers\n",
      "Processed 18700 papers\n",
      "Processed 18800 papers\n",
      "Processed 18900 papers\n",
      "Processed 19000 papers\n",
      "Processed 19100 papers\n",
      "Processed 19200 papers\n",
      "Processed 19300 papers\n",
      "Processed 19400 papers\n",
      "Processed 19500 papers\n",
      "Processed 19600 papers\n",
      "Processed 19700 papers\n",
      "Processed 19800 papers\n",
      "Processed 19900 papers\n",
      "Processed 20000 papers\n"
     ]
    }
   ],
   "source": [
    "def create_subset(metadata, subset_metadata_path, max_papers=1000):\n",
    "    # Subset of the metadata with publish date extracted\n",
    "    subset_metadata = []\n",
    "\n",
    "    with open(subset_metadata_path, 'w') as json_file:\n",
    "        pass\n",
    "\n",
    "    # Iterate through each paper in the metadata\n",
    "    num_processed = 0\n",
    "\n",
    "    for i, paper_info in enumerate(metadata):\n",
    "\n",
    "        # Skip papers that are not in the CS category\n",
    "        categories = paper_info.get('categories')\n",
    "        if not (' cs.' in categories or categories.startswith('cs.')):\n",
    "            continue\n",
    "\n",
    "        paper_dict = {\n",
    "            'id': paper_info.get('id'),\n",
    "            'title': paper_info.get('title'),\n",
    "            'abstract': paper_info.get('abstract'),\n",
    "            'categories': paper_info.get('categories'),\n",
    "            'submit_date': get_v1_submission_date(paper_info)\n",
    "        }\n",
    "\n",
    "        subset_metadata.append(paper_dict)\n",
    "\n",
    "        if num_processed % 100 == 0:\n",
    "            append_to_file(subset_metadata, subset_metadata_path)\n",
    "            print(f\"Processed {num_processed} papers\")\n",
    "            subset_metadata = []\n",
    "\n",
    "        num_processed += 1\n",
    "\n",
    "        if num_processed > max_papers:\n",
    "            break\n",
    "\n",
    "clear_file(subset_metadata_path)\n",
    "create_subset(metadata, subset_metadata_path, max_papers=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"0712.1359\", \"title\": \"Borel Ranks and Wadge Degrees of Context Free Omega Languages\", \"abstract\": \"  We show that, from a topological point of view, considering the Borel and the\\nWadge hierarchies, 1-counter B\\\\\\\"uchi automata have the same accepting power\\nthan Turing machines equipped with a B\\\\\\\"uchi acceptance condition. In\\nparticular, for every non null recursive ordinal alpha, there exist some\\nSigma^0_alpha-complete and some Pi^0_alpha-complete omega context free\\nlanguages accepted by 1-counter B\\\\\\\"uchi automata, and the supremum of the set\\nof Borel ranks of context free omega languages is the ordinal gamma^1_2 which\\nis strictly greater than the first non recursive ordinal. This very surprising\\nresult gives answers to questions of H. Lescow and W. Thomas [Logical\\nSpecifications of Infinite Computations, In:\\\"A Decade of Concurrency\\\", LNCS\\n803, Springer, 1994, p. 583-621].\\n\", \"categories\": \"cs.LO cs.GT math.LO\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1363\", \"title\": \"Undecidable Problems About Timed Automata\", \"abstract\": \"  We solve some decision problems for timed automata which were recently raised\\nby S. Tripakis in [ Folk Theorems on the Determinization and Minimization of\\nTimed Automata, in the Proceedings of the International Workshop FORMATS'2003,\\nLNCS, Volume 2791, p. 182-188, 2004 ] and by E. Asarin in [ Challenges in Timed\\nLanguages, From Applied Theory to Basic Theory, Bulletin of the EATCS, Volume\\n83, p. 106-120, 2004 ]. In particular, we show that one cannot decide whether a\\ngiven timed automaton is determinizable or whether the complement of a timed\\nregular language is timed regular. We show that the problem of the minimization\\nof the number of clocks of a timed automaton is undecidable. It is also\\nundecidable whether the shuffle of two timed regular languages is timed\\nregular. We show that in the case of timed B\\\\\\\"uchi automata accepting infinite\\ntimed words some of these problems are Pi^1_1-hard, hence highly undecidable\\n(located beyond the arithmetical hierarchy).\\n\", \"categories\": \"cs.LO cs.CC math.LO\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1365\", \"title\": \"Population stratification using a statistical model on hypergraphs\", \"abstract\": \"  Population stratification is a problem encountered in several areas of\\nbiology and public health. We tackle this problem by mapping a population and\\nits elements attributes into a hypergraph, a natural extension of the concept\\nof graph or network to encode associations among any number of elements. On\\nthis hypergraph, we construct a statistical model reflecting our intuition\\nabout how the elements attributes can emerge from a postulated population\\nstructure. Finally, we introduce the concept of stratification\\nrepresentativeness as a mean to identify the simplest stratification already\\ncontaining most of the information about the population structure. We\\ndemonstrate the power of this framework stratifying an animal and a human\\npopulation based on phenotypic and genotypic properties, respectively.\\n\", \"categories\": \"q-bio.PE cs.AI physics.data-an\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1400\", \"title\": \"Birthday attack to discrete logarithm\", \"abstract\": \"  The discrete logarithm in a finite group of large order has been widely\\napplied in public key cryptosystem. In this paper, we will present a\\nprobabilistic algorithm for discrete logarithm.\\n\", \"categories\": \"cs.CR\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1402\", \"title\": \"Reconstruction of Markov Random Fields from Samples: Some Easy\\n  Observations and Algorithms\", \"abstract\": \"  Markov random fields are used to model high dimensional distributions in a\\nnumber of applied areas. Much recent interest has been devoted to the\\nreconstruction of the dependency structure from independent samples from the\\nMarkov random fields. We analyze a simple algorithm for reconstructing the\\nunderlying graph defining a Markov random field on $n$ nodes and maximum degree\\n$d$ given observations. We show that under mild non-degeneracy conditions it\\nreconstructs the generating graph with high probability using $\\\\Theta(d\\n\\\\epsilon^{-2}\\\\delta^{-4} \\\\log n)$ samples where $\\\\epsilon,\\\\delta$ depend on the\\nlocal interactions. For most local interaction $\\\\eps,\\\\delta$ are of order\\n$\\\\exp(-O(d))$.\\n  Our results are optimal as a function of $n$ up to a multiplicative constant\\ndepending on $d$ and the strength of the local interactions. Our results seem\\nto be the first results for general models that guarantee that {\\\\em the}\\ngenerating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}\\n\\\\epsilon^{-2}\\\\delta^{-4} \\\\log n)$ running time bound. In cases where the\\nmeasure on the graph has correlation decay, the running time is $O(n^2 \\\\log n)$\\nfor all fixed $d$. We also discuss the effect of observing noisy samples and\\nshow that as long as the noise level is low, our algorithm is effective. On the\\nother hand, we construct an example where large noise implies\\nnon-identifiability even for generic noise and interactions. Finally, we\\nbriefly show that in some simple cases, models with hidden nodes can also be\\nrecovered.\\n\", \"categories\": \"cs.CC cs.LG\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1442\", \"title\": \"On types of growth for graph-different permutations\", \"abstract\": \"  We consider an infinite graph G whose vertex set is the set of natural\\nnumbers and adjacency depends solely on the difference between vertices. We\\nstudy the largest cardinality of a set of permutations of [n] any pair of which\\ndiffer somewhere in a pair of adjacent vertices of G and determine it\\ncompletely in an interesting special case. We give estimates for other cases\\nand compare the results in case of complementary graphs. We also explore the\\nclose relationship between our problem and the concept of Shannon capacity\\n\\\"within a given type\\\".\\n\", \"categories\": \"math.CO cs.IT math.IT\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1499\", \"title\": \"On the computational complexity of cut-reduction\", \"abstract\": \"  Using appropriate notation systems for proofs, cut-reduction can often be\\nrendered feasible on these notations, and explicit bounds can be given.\\nDeveloping a suitable notation system for Bounded Arithmetic, and applying\\nthese bounds, all the known results on definable functions of certain such\\ntheories can be reobtained in a uniform way.\\n\", \"categories\": \"cs.LO cs.CC\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1519\", \"title\": \"Discrete Nondeterminism and Nash Equilibria for Strategy-Based Games\", \"abstract\": \"  Several notions of game enjoy a Nash-like notion of equilibrium without\\nguarantee of existence. There are different ways of weakening a definition of\\nNash-like equilibrium in order to guarantee the existence of a weakened\\nequilibrium. Nash's approach to the problem for strategic games is\\nprobabilistic, \\\\textit{i.e.} continuous, and static. CP and BR approaches for\\nCP and BR games are discrete and dynamic. This paper proposes an approach that\\nlies between those two different approaches: a discrete and static approach.\\nmulti strategic games are introduced as a formalism that is able to express\\nboth sequential and simultaneous decision-making, which promises a good\\nmodelling power. multi strategic games are a generalisation of strategic games\\nand sequential graph games that still enjoys a Cartesian product structure,\\n\\\\textit{i.e.} where agent actually choose their strategies. A pre-fixed point\\nresult allows guaranteeing existence of discrete and non deterministic\\nequilibria. On the one hand, these equilibria can be computed with polynomial\\n(low) complexity. On the other hand, they are effective in terms of\\nrecommendation, as shown by a numerical example.\\n\", \"categories\": \"cs.GT\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1521\", \"title\": \"Graphs and Path Equilibria\", \"abstract\": \"  The quest for optimal/stable paths in graphs has gained attention in a few\\npractical or theoretical areas. To take part in this quest this chapter adopts\\nan equilibrium-oriented approach that is abstract and general: it works with\\n(quasi-arbitrary) arc-labelled digraphs, and it assumes very little about the\\nstructure of the sought paths and the definition of equilibrium, \\\\textit{i.e.}\\noptimality/stability. In this setting, this chapter presents a sufficient\\ncondition for equilibrium existence for every graph; it also presents a\\nnecessary condition for equilibrium existence for every graph. The necessary\\ncondition does not imply the sufficient condition a priori. However, the\\nchapter pinpoints their logical difference and thus identifies what work\\nremains to be done. Moreover, the necessary and the sufficient conditions\\ncoincide when the definition of optimality relates to a total order, which\\nprovides a full-equivalence property. These results are applied to network\\nrouting.\\n\", \"categories\": \"cs.GT\", \"submit_date\": [12, 2007]}\n",
      "{\"id\": \"0712.1529\", \"title\": \"Ontology and Formal Semantics - Integration Overdue\", \"abstract\": \"  In this note we suggest that difficulties encountered in natural language\\nsemantics are, for the most part, due to the use of mere symbol manipulation\\nsystems that are devoid of any content. In such systems, where there is hardly\\nany link with our common-sense view of the world, and it is quite difficult to\\nenvision how one can formally account for the considerable amount of content\\nthat is often implicit, but almost never explicitly stated in our everyday\\ndiscourse. The solution, in our opinion, is a compositional semantics grounded\\nin an ontology that reflects our commonsense view of the world and the way we\\ntalk about it in ordinary language. In the compositional logic we envision\\nthere are ontological (or first-intension) concepts, and logical (or\\nsecond-intension) concepts, and where the ontological concepts include not only\\nDavidsonian events, but other abstract objects as well (e.g., states,\\nprocesses, properties, activities, attributes, etc.) It will be demonstrated\\nhere that in such a framework, a number of challenges in the semantics of\\nnatural language (e.g., metonymy, intensionality, metaphor, etc.) can be\\nproperly and uniformly addressed.\\n\", \"categories\": \"cs.AI cs.CL\", \"submit_date\": [12, 2007]}\n"
     ]
    }
   ],
   "source": [
    "# Open the file and read its contents\n",
    "num_first_lines = 10\n",
    "with open(subset_metadata_path, 'r') as json_file:\n",
    "    # Read the first 10 lines\n",
    "    first_10_lines = [json_file.readline().strip() for _ in range(num_first_lines)]\n",
    "\n",
    "# Print the first 10 lines of the file\n",
    "for line in first_10_lines:\n",
    "    print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_metadata_path_without_concepts = \"/mnt/qnap/liranc6/data/con_graph/dataset/subset_metadata.json\"\n",
    "subset_metadata_path_with_concepts = \"/mnt/qnap/liranc6/data/con_graph/dataset/subset_metadata_with_concepts.json\"\n",
    "corpus_path = \"/home/liranc6/con_graph/corpus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(a)=66\n"
     ]
    }
   ],
   "source": [
    "a = set()\n",
    "metadata_with_concepts = get_metadata(subset_metadata_path_with_concepts)\n",
    "for i, paper in enumerate(metadata_with_concepts):\n",
    "    for c in paper['concepts']:\n",
    "        a.update(c)\n",
    "        # print()\n",
    "\n",
    "    # print(\"\\n\")\n",
    "    if i > 100:\n",
    "        break\n",
    "\n",
    "print(F\"{len(a)=}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = \"/mnt/qnap/liranc6/data/con_graph/dataset/tmp.json\"\n",
    "\n",
    "def str_list_to_lower(lst):\n",
    "    return [x.lower() for x in lst]\n",
    "\n",
    "corpus = set()\n",
    "with open(tmp_path, 'w') as g:\n",
    "    for i, paper in enumerate(get_metadata(subset_metadata_path_with_concepts)):\n",
    "        # paper['concepts'] = str_list_to_lower(paper['concepts'])\n",
    "        corpus.update(paper['concepts'])\n",
    "        # json.dump(paper, g)\n",
    "\n",
    "print(f\"{len(corpus)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(corpus)=7317\n"
     ]
    }
   ],
   "source": [
    "with open(corpus_path, 'w') as corpus_file:\n",
    "            print(f\"{len(corpus)=}\")\n",
    "            corpus = '\\n'.join(corpus)    \n",
    "            corpus_file.write(corpus + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0906.4492', 'title': 'Efficient Generation of Craig Interpolants in Satisfiability Modulo\\n  Theories', 'abstract': '  The problem of computing Craig Interpolants has recently received a lot of\\ninterest. In this paper, we address the problem of efficient generation of\\ninterpolants for some important fragments of first order logic, which are\\namenable for effective decision procedures, called Satisfiability Modulo Theory\\nsolvers.\\n  We make the following contributions.\\n  First, we provide interpolation procedures for several basic theories of\\ninterest: the theories of linear arithmetic over the rationals, difference\\nlogic over rationals and integers, and UTVPI over rationals and integers.\\n  Second, we define a novel approach to interpolate combinations of theories,\\nthat applies to the Delayed Theory Combination approach.\\n  Efficiency is ensured by the fact that the proposed interpolation algorithms\\nextend state of the art algorithms for Satisfiability Modulo Theories. Our\\nexperimental evaluation shows that the MathSAT SMT solver can produce\\ninterpolants with minor overhead in search, and much more efficiently than\\nother competitor solvers.\\n', 'categories': 'cs.LO', 'submit_date': [6, 2009], 'concepts': ['satisfiability modulo theory', 'first order logic', 'interpolation problem', 'craig interpolants', 'decision procedures', 'theory combination', 'linear arithmetic', 'difference logic', 'utvpi theory', 'mathsat smt solver']}\n"
     ]
    }
   ],
   "source": [
    "for p in get_metadata(subset_metadata_path_with_concepts):\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "len(c2)=205\n"
     ]
    }
   ],
   "source": [
    "c2 = set()\n",
    "for i, p in enumerate(get_metadata(subset_metadata_path_with_concepts)):\n",
    "    c2.update(p['concepts'])\n",
    "    # print(i)\n",
    "\n",
    "print(i)\n",
    "print(f\"{len(c2)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['microelectrode design', 'information integration', 'feasibility tests', 'distributed systems', 'bandwidth allocation', 'architecture design', 'routing games', 'automated theorem proving', 'edge-based routing', 'hasse diagrams visualization', 'semantic modeling', 'streaming data analysis', 'entanglement representation', 'transaction management', 'probabilistic argumentation systems', 'maximum-weight balanced cut', 'loss-leader pricing', 'computational complexity', 'package fabrication', 'etching techniques', 'vertex-wise budgeting', 'password authentication', 'electrical properties', 'computational neuroscience', 'stokes flow solvers', 'instantaneous power constraint', 'game theory', 'spreadsheet error-checking', 'computational overhead', 'shannon capacity', 'channel coding theory', 'morphing algorithm', 'kronecker product algorithm', 'minimum mean-square error', 'half-duplex operation', 'system reliability', 'edge congestion', 'vertical partitioning', 'scaling window estimation', 'polytope family definition', 'unfolding', 'information transmission', 'channel machines', 'nio sensing layer', 'non-binary codes', 'ion diffusion', 'message delay optimization', 'usability testing', 'complex systems', 'additive white gaussian noise', 'refining techniques', 'property proving', 'signal processing techniques', 'wafer bonding', 'pairwise independent distributions', 'rate-limited links', 'data stream processing', \"merkle's key agreement\", 'blended learning platforms', 'mathematical metrics', 'space curve analysis', 'error locator polynomial', 'code inspection', 'lattice coding', 'thin film technology', 'multidimensional signal processing', 'computer science research', 'course organization', 'minimum in-degree', 'quantized channel output', 'medium access control', 'latin hypercubes', '5-speed optimality', 'decentralized systems', 'lightweight protocols', 'risk management strategies', 'recurrent patterns', 'analytical performance evaluation', 'orientation problem', 'bivariate chromatic polynomial', 'efficient solution methods', 'bit error rate', 'wet etching fabrication', 'evolutionary systems', 'insecure authentication methods', 'taylor series expansion', 'multi-dimensional data', 'siso mimo', 'proof search algorithms', 'optical interferometry measurements', 'image classification', 'noncoherent communication', 'mold simulation', 'chip formation process', 'multiple access techniques', 'rural areas development', 'gaussian multiple-access networks', 'omega context free', 'plane curve theory', 'www image retrieval', 'array operations', 'thermal conversion', 'programming constructs', 'edge addition algorithm', 'program verification', 'patterned layer etching', 'bit-optimal parsing', 'causal transform coding', 'communication complexity of set disjointness', 'convolution operation in min-plus algebra', 'bayesian optimization', 'data stream statistics', 'dlp system implementation', 'rank weight', 'synchronizer element', 'stable distributions', 'mathematical logic', 'drop-when-seen algorithm', 'independent identically distributed', 'llr domain implementation', 'combinatorial objects', 'nominal compounds', 'fixed vertex count', 'ergodic mutual information', 'web survey methodology', 'normal form translation', 'well-moded programs', 'half duplex transmission', 'sparse graphs', 'data mining techniques', 'external storage optimization', 'packaging stress', 'efficiency optimization', 'borel complexity', 'experimental design', 'fine-pitch solder balling methods', 'interferers and noise', 'double spending prevention', 'preimage attacks', 'graph theory applications', 'distributed model predictive control (dmpc)', 'elliptic curve cryptography', 'unique solution problem', 'trust-based systems', 'self-orthogonal codes', 'kuratowski graph', 'graphical games', 'thin film deposition', 'service curve theory', 'retransmission protocols', 'shannon theory', 'channel state estimation', 'quantified formulas evaluation', 'linear program formulation', 'directed tree-width', 'parser evaluation', 'carrier frequency offsets', 'operating systems', 'frequency selective channels', 'monadic second order', 'snp vs se containment', 'graph optimization', 'microelectromechanical systems', 'minimization', 'algorithmic universe', 'octonion algebra', 'interference cancellation', 'fibonacci cobweb', 'security and trust models', 'synchronization techniques', 'subgraph problem', 'protocol verification', 'surfels parametrization', 'gyroscope technology', 'pulse synchronization problem', 'np-hardness', 'barbed bisimilarity', 'substitution attacks', 'mass flow sensors', 'thread parallelism', 'deterministic methods', 'error measurement', 'coinductive reasoning', 'markov model evolution', 'computer science theory', 'bargaining problems', 'lower bounds proofs', 'uniform outdegree', 'rational numbers', 'computer science metrics', 'substitution method improvement', 'compression techniques', 'blink detection', 'episturmian words', 'mobile computing', 'wireless ad-hoc networks', 'logic-based systems', 'system design principles', 'attack graph', 'array computation', 'stream ciphers', 'model integrity control', 'edge coloring', 'cardinality constraints', 'maximum-likelihood detection (mld)', 'prostate volume definition', 'decidable complexity', 'run-length encoding', 'computer science fundamentals', 'self-adjusting selective pressure', 'synchronizer node validity', 'grid computing', 'semiunitary matrices', 'logic-based methods', 'euclidean geometry', 'service oriented design', 'two-user channel', 'secondary user transmission', 'call-by-value', 'd-optimality criterion', 'exponential sums', 'diagramming techniques', 'material property measurement', 'analog signals', 'computer-aided design', 'medical device development', 'error probability bounds', 'np-hard problems', 'non-linear analysis', 'fluid dynamics', 'error detection techniques', 'high dimensional distributions', 'formula error detection', 'wyner-ziv coding', 'resolution proofs', 'mobile systems', 'optimal codes', 'linear real arithmetic', 'ubiquitous devices', 'directive words', 'capability-based access', 'low density parity check', 'polynomial time complexity', 'convex arcs', 'alternative input methods', 'groove profile control', 'diversity sum', 'optical waveguide fabrication', 'tap position optimization', 'artificial intelligence', 'prototyping process', 'alloy language', 'hierarchical systems', 'coauthorship network', 'asymmetric systems', 'human-computer interaction', 'poset algebraic structures', 'ghanaian medical community development', 'simulation theory', 'deadlock detection', 'interior-point method', 'self-organizing neural systems', 'pareto distribution', 'noisy input handling', 'euclidean spanners', 'algebraic specification', 'java programming language', 'max csp problems', 'non context free languages', 'code design', 'symmetric primitives', 'object access mechanisms', 'convergence radius', 'formal semantics of programming languages', 'micro-pump design', 'zero-forcing equalization', 'job flow analysis', 'nash equilibrium analysis', 'closed-form expressions', 'partial differential equations', 'bethe free energy', 'quadratic update rules', 'sampling techniques', 'lumped element model', 'authentication methods', 'adversarial environments', 'instruction sequence translation', 'anonymous networks', 'byzantine fault resilient communication', 'advanced lighting techniques', 'spreadsheet design', 'sensor output filtering', 'wiretap channel', 'computable functions', 'passive network measurements', 'nature inspired algorithms', 'high-dimensional data', 'graph dynamics', 'pure morphisms', 'algebraic curves', 'scalable optimization', 'packet erasure', 'synchronized colorings techniques', 'microstructured mold', 'polynomial performance', 'bandwidth estimation', 'higher-order logic', 'hermite-korkine-zolotarev', 'email corpus analysis', 'algorithmic geometry', 'phylogenetic reconstruction', 'coalgebraic approach methods', 'context free languages', 'infinite words generation', 'tree-width measures', 'continuum model', 'qubit-flip errors', 'linear iterative algorithms', 'comparative study of users', 'independent samples', 'disjointness function', 'probabilistic iterative procedures', 'polynomial constraints', 'program transformation', 'line bundles', 'network selection', 'point set processing', 'signal-to-noise ratio', 'differential privacy', 'channel analysis', 'temporal pattern discovery', 'gaussian distributions', 'erasure option', 'lateral interconnect technologies', 'zeta transforms', 'linear time invariant', 'hierarchical optimization', 'olsr protocol', 'gauge transformation', 'dynamic data structures', 'bounded list size', 'bit error probability', 'community networking', 'disaster recovery', 'rate-distortion tradeoff analysis', 'micromachining', 'coverage maximization', 'middleware technology', 'erank algorithms', 'polymer deformation', 'modulation schemes', 'residual stress analysis', 'graph connectivity measures', 'fibonacci sequence analysis', 'linear channels with isi', 'self-starved overload control (soc) policy', 'disability inclusion', 'multi-group decoding', 'subset sum problem', 'statistical performance evaluation', 'markovian channels', 'spreadsheet programs', 'np-hardness results', 'replica symmetry breaking', 'brown-minder-shokrollahi algorithm', 'base structure theory', 'artificial intelligence systems', 'integrated systems', 'teaching methods', 'adaptive algorithms', 'distributed storage systems', 'preconditioning techniques', 'computational model', 'categorical semantics', 'safe-bounded-mean-delay (sbmd) throughput', 'parallel manipulators', 'low-density generator matrix', 'x-axis tuning fork gyroscope', 'error exponents', 'sequence analysis techniques', 'gyroscope design', 'asynchronous capacity', 'combinatorial constructions', 'near neighbor interactions', 'enhanced security', 'chaotic sequences', 'optimization techniques', 'shannon entropy', 'substitution algebra', '4-way key pad selection', 'edge dependence factors', 'nonlinear methods', 'bandwidth limitation', 'non-autonomous threads', 'social network analysis', 'linear segments', 'skos encoding', 'implicit methods', 'information conservation', 'cell path metrics', 'dna computing devices', 'deterministic broadcasting', 'parity functions', 'spring-mass systems', 'microelectronics integration', 'gnu/linux security', 'strong components', 'sphere decoding', 'han-kobayashi scheme', 'sofic shifts', 'quantifier elimination techniques', 'pixel expansion issues', 'information technology', 'iterative decoding threshold', 'portable persistence', 'collective intelligence', 'network communication', 'distributed reception', 'locally decodable', 'number theory applications', 'image segmentation algorithms', 'coding scheme optimization', 'auto regression', 'tree alignment problem', 'labeled weighted graph matching', 'spreadsheet auditing technique', 'simple regret criterion', 'orthogonal tree flattening', 'two-bit matchgates', 'micro electro mechanical systems', 'decoding methods', 'data hiding techniques', 'dissection theory', 'truthful mechanism design', 'geographic information', 'wideband signal processing', 'market data analysis', 'resonator design', 'min max algorithm', 'anisotropic materials', 'privacy preservation', 'constraint solving', 'lac operon', 'probabilistic pushdown automata', 'testing schemes', 'machine learning', 'bittorrent protocol', 'pebbling contradictions', 'internet congestion', 'flat fading', 'speech synthesis', 'model flaws', 'condition block modeling', 'logic formula generation', 'universal coding', 'rf resonators', 'code review', 'optical imaging systems', 'computational semantics', 'hansen-pedersen-jensen inequality', 'multiple antennas', 'word patterns', 'cech complex filtration', 'discrete logarithms', 'sampling algorithms', 'network flow', 'international standards', 'terrestrial broadcasting standards', 'sum rate optimization', 'signal frequency', 'notation systems', 'muchnik iteration', 'authentication mechanisms', 'gaussian frequency-selective interference channel', 'feedback networks', 'non-constant length substitution', \"mar\\\\'{e}chal's extended perspectives\", 'tensor product spaces', 'route optimization problem', 'chemometry applications', 'temporal logic', 'routing protocols design', 'collaborative filtering technology', 'polycrystalline silicon germanium', 'end-user development', 'language dynamics analysis', 'multiple access networks', 'analytical modeling methods', 'aloha protocol', 'proxy revocation', 'fault tracing', 'instruction sequences analysis', 'reconfigurable circuit design', 'binding dynamics', 'vertex-induced subgraphs', 'gyroscope sensors', 'query complexity', 'immersed boundary method', 'anonymization techniques', 'computational complexity analysis', 'realizable bargains', 'timed quorum system', 'max cut and max dicut problems', 'non-coherent channels', 'rees algebra theory', 'cascaded rf circuit analysis', 'graph theory framework', 'opportunistic relaying', 'massive datasets', 'secure authentication protocols', 'global system monitoring', 'gaussian distribution', 'citation analysis', 'domain knowledge extraction', 'predicate logic', 'distributed control', 'bi-criteria mapping', 'word processing', 'gaussian functions', 'complement problem', 'decoding order', 'hybrid optimization', 'coverage region approximation', 'decoder optimization', 'spreadsheet computations', 'rate-distortion theory', 'noiseless transmission', 'flow rate measurement', 'pairing-based signatures', 'healthcare informatics', 'fidelity criterion', 'micro-tensile testing', 'finite size effects', 'learning management', 'image steganography', 'artificial cosmogenesis', 'language generation', 'text summarization', 'real traces analysis', 'prime reciprocals', 'location-based services', 'reducibility arguments', 'execution semantics analysis', 'experimental validation methods', 'learner monitoring', 'wireless technologies', 'intersection problem', 'transmit signal covariance matrices', 'equilibrium conditions', 'lambda calculus', 'capacity region', 'stream computing', 'scheduling', 'string matching', 'nl and sc classes', 'density estimation', 'regular graphs', 'finite words', 'backend services', 'decision making', 'consensus algorithms', 'decision theory', 'time-delayed systems', 'linear network coding', 'dynamic constraint management', 'nitride thin film properties', 'critical behavior', 'delay differential', 'entropy set cover', 'fast extended euclidean algorithm', 'error reduction', 'assistive technologies', 'backpropagation algorithm', 'medium access protocols', 'surgical navigation systems', 'blocking sets theory', 'cobweb poset construction', 'matrix completion', 'risk management', 'glass transition temperature', 'entropy estimation methods', 'reachability problems', 'dynamic graph visualizer', 'ferromagnetic materials', 'logarithmic bounds', 'remote expertise', 'paradigm shift', 'directed graph traversal', 'wavelet analysis', 'component-based software engineering', 'electromagnetic generators', 'remote authentication', 'projection methods', 'gaussian sources', 'nonlinear systems', 'higher-order functions', 'undirected graphs', 'wiki-based documentation', 'distributed consensus algorithms', 'thermo-mechanical modeling', 'formatting preservation', 'minimum entropy', 'semi-analytical methods', 'price of anarchy', 'sum rate capacity', 'virtual research environment', 'matrix theory', 'microsensors', 'employee empowerment', 'pervasive computing', 'quasi-aperiodic languages', 'embedded processor technology', 'auditing and certification', 'deconvolution methods', 'automated spreadsheet control', 'functional decomposition', 'set cover modelling', 'semantic wikis', 'separating pairs graphs', 'antibody antibody interaction', 'tiling theory', 'high-throughput computing architecture', 'suboptimal solution techniques', 'secure channels', 'polynomial encoding', 'subdivision schemes', 'spectral density estimation', 'udp traffic analysis', 'numerical methods', 'context awareness', 'interior-point methods', 'adaptive backoff mechanisms', 'deterministic reconstruction', 'proxy signatures', 'network congestion', 'gaussian noise modeling', 'continuous variables', 'quantum entropy', 'word networks', 'many-one completeness', 'mean payoff games', 'nonparametric methods', 'measurement tools', 'hierarchical clustering', 'active vision systems', 'omega power', 'np complexity class', 'systemc/c++ modeling', 'malware detection', 'adaptive speed adjustment', 'carbon based epoxy resin', 'modular design', 'ontology development', 'recursively balanced matrices', 'equivariance principle', 'power conversion', 'vector space model', 'random sequences', 'population dynamics', 'reductions from related problems', 'network capacity', 'dual gap capacitor', 'matrix optimization strategies', 'noise thresholds', 'numerical computations', 'polytope representation', 'number-on-the-forehead model', 'interference modeling', 'check matrix generation', 'user behavior analysis', 'real-time feedback', 'reliable packet communication', 'random filtering', 'process modeling', 'research collaboration', 'probabilistic polynomial time', 'crossdock centre operations', 'database management', 'graph colorings algorithms', 'error prevention methods', 'factorization problem', 'simulation-based design', 'voice over internet protocol', 'q-extensions formulas', 'linguistic modelling', 'full-text search engines', 'load balancing', 'cognitive radio algorithms', 'error-correcting data structures', 'structural redundancy detection', 'distributed key predistribution', 'two-party protocols', 'bulk-micromachining technology', 'random fractal modeling', 'ptas (polynomial time approximation scheme)', 'branch and bound', 'pointer jumping problem', 'coil design', 'traffic analysis', 'dynamical processes', 'memory access patterns', 'online permutation learning algorithm', 'program fragmentation problem', 'unit disk graphs', 'epsilon-transmissibility', 'oracle complexity', 'low-redundancy codes', 'modeling techniques', 'nurse scheduling problem', 'contiguous sequence analysis', 'complexity theory', 'competitive analysis', 'iteration constructs', 'mems devices', 'algebraic functions', 'multipath fading', 'nanostructural probes', 'decomposition methods', 'network security', 'zigbee technology', 'relational algebra operations', '$\\\\ell_2^2$ distance in frequencies', 'boltzmann-gibbs statistical behavior', 'extended access control', 'optimal smoothers', 'computing power', 'cut-restricted proof systems', 'geodesic distances', 'object contribution', 'interference channels', 'synchronous multiuser uplink', \"verdu-han's lemma\", 'transmission optimization', 'combinatorial optimisation', 'octree data structure', 'image retrieval', 'man-in-the-middle attack', 'computer literacy', 'low-density parity-check codes', 'topology-based algorithms', 'homology class measurement', 'optimization algorithm', 'pulsed digital oscillator', 'sensor integration', 'strongly maximum distance separable', 'capacity pre-loglog analysis', 'control system design', 'journal of discrete algorithms', 'deep learning frameworks', 'hypercube graph', 'real-time threat response', 'wavelet packet decomposition', 'extended coherent states', \"master's programs\", 'sigma^1_1-completeness', 'metonymy resolution', 'qwaq forums platform', 'nonlinear dynamics', 'vertex shifting algorithm', 'forestry research journals', 'bioinformatics data integration', 'ambient energy scavenging', 'cooperative play', 'constructive independence', 'fiber coupling optimization', 'burst-error correction', 'image fusion', 'adjacency matrices', 'excelsior software', 'collaborative work analysis', 'bidirectional search', 'online communities', 'tissue engineering', 'healthcare economics', 'code theory', 'overconstrained 3d translational mechanisms', 'quantum error', 'dpll heuristics', 'id3 algorithm', 'linear complexity detection', 'coupled map lattice', 'coded and uncoded side information', 'algebraization of graph grammars', 'link scheduling', 'computer aided design cad', 'maximum entropy models', 'web-based applications', 'nonbinary codes construction', 'multi-modal vibration analysis', 'low-density parity', 'multidimensional codes', 'programmable logic devices', 'business applications', 'software updates', 'constraint handling rules', 'accessibility metrics', 'hidden convexity', 'machine learning evaluation', 'nonlinear dynamics modeling', 'sparse data processing', 'user experience study', 'concrete materials science', 'active edge hypothesis', 'thin film lamination', 'time-sharing randomized sequence', 'descending-price auction', 'scheffe tournament', 'ising p-spin model', 'liquid filling mechanism', 'extended euclidean algorithm', 'local transition functions', 'permutation array construction', 'robot control systems', 'polynomial ambiguity', 'knowledge management', 'transducers', 'adaptive source coding', 'concept classes', 'exploration-exploitation tradeoff', 'mimo transmission', 'myopic policy optimization', 'human-computer interaction analysis', 'check node processing', 'secure data sharing', 'etching parameters', 'data analysis', 'balance property connection', 'spreadsheet risk reduction', 'noisy links', 'dynamic systems analysis', 'superposition coding', 'denjoy counterexamples', 'fidelity constraints', 'ontologies', 'semi-definite programming', 'virtual springs simulation', 'pivoting-free methods', 'decode-and-forward protocol', 'spanning trees', 'word combinatorics', 'multiple access', 'random walk process', 'blind optimization', 'graph structure analysis', 'sensor identification', 'cut-set bound', 'multifractal signal processing', 'optimal stopping theory', 'vibration-based pumping', 'binary operations', 'matroid theory applications', 'prediction algorithms', 'cooperative game', 'agent communication', 'graph order', 'case-based reasoning', 'entropy landscape', 'rotated space-time codes', '1.6737-approximation mechanism', 'rate achievability', 'agent-based framework', 'gate circuit design', 'marcum q-function', 'wireless communication', 'deadline scheduling', 'stability number', 'micro-generator rectifier conditioner', 'hybrid systems', 'computer architecture', 'system optimization', 'action graph games', 'mechanical energy', 'e-science', 'concave function optimization', 'authorization protocols', 'vapnik-chervonenkis dimension', 'microelectronic systems', 'language simulation models', 'mems oscillator', 'complete dag construction', 'hamming weight enumerator', 'f-nomial coefficients', 'opportunistic scheduling (os)', 'protocol parameters', 'quality of service requirements', 'replica method', 'contextual word prediction', 'user error prevention', 'prostate cancer treatment', 'ingleton inequalities', 'sinr model', 'symmetric monoidal categories', 'symbolic dynamics', 'weakness detection', 'random access', 'mobius ladders', 'sum-rate maximization', 'randomization techniques', 'bicoloring problem', 'european internet', 'time series modeling', 'scalable systems', 'time-varying channels', 'automated review', 'algebraic consequences', 'genetic algorithm optimization', 'microwave technology', 'modelling language', 'pressure sensors', 'logarithmic time complexity', 'communication performance', 'binary erasure channel', 'cyclic systems', 'rule annotation', 'complex systems modelling', 'bioinformatics algorithms', 'game theory applications', 'web scraping methods', 'rf component characterization', 'spreadsheet security', 'markov decision processes', 'optical performance modeling', 'cultural evolution', 'industry cluster', 'dendritic cells', 'simulation-based reality', 'gcd morphism problem', 'packaging methods', 'population stratification', 'network ranking', 'organizational capabilities', 'adaptive-chosen-ciphertext attack', 'network technologies', 'augmenting path algorithm', 'information rate optimization', 'thermopile fabrication and testing', 'automated spreadsheet modification', 'resolution limitation', 'change management', 'plate extension impact', 'weighted graph embeddings', 'complex eigenvalues detection', 'cryptography methods', 'entropy power inequality', 'piezoelectric devices', 'corporate bond market modeling', 'gaussian distribution approximation', 'capacity scaling laws', 'mathematical programming techniques', 'graph classes', 'polynomial time computation', 'silicon nanopore fabrication', 'static games', 'l1-norm approximation', 'output power prediction', 'background subtraction', 'hyperbolic geometry', 'routing protocols optimization', 'materials science', 'computer languages', 'maximize total weight', 'counter examples construction', 'modal logics', 'discrete modeling', 'character matrices', 'ultrasound technology', 'boolean function synthesis', 'classical linear codes', 'adversarial queries', 'corporate governance tools', 'm-sequences distribution study', 'authentication theory', 'numerical optimization', 'loopy graph', 'entropy conjectures', 'spreadsheet technology', 'system theoretic network modeling', 'doubly stochastic matrices', 'extreme learning machine', 'algebraic formulas', 'modified information transmission', 'virtual coordinates', 'hard gaps in max csp', 'linear programming duality', 'projective geometry', 'performance metrics', 'variable-length codewords', 'quantum-like decision making', 'rayleigh fading channels', 'minimum distance estimation', 'node probing', 'configuration management', 'false alert detection', 'undirected graph induction', 'betti number', 'convex sets computation', \"harju-karhumaki's result\", 'tuplix calculus', 'random sequence generation', 'social cost']\n"
     ]
    }
   ],
   "source": [
    "with open(corpus_path, 'r') as f:\n",
    "    corpus = f.read().split('\\n')\n",
    "\n",
    "print(corpus[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_subset = \"/mnt/qnap/liranc6/data/con_graph/dataset/save_subset.json\"\n",
    "save_corpus = \"/mnt/qnap/liranc6/data/con_graph/dataset/save_corpus.txt\"\n",
    "\n",
    "!cp {subset_metadata_path_with_concepts} {save_subset}\n",
    "!cp {corpus_path} {save_corpus}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "con_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
